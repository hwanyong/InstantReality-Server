{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd #현재 위치 기준 환경 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2c2c18",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81678463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai \n",
    "from google.genai import types\n",
    "import json\n",
    "import textwrap\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "import dataclasses\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from PIL import ImageColor, ImageDraw, ImageFont\n",
    "from typing import Tuple\n",
    "import IPython\n",
    "from IPython import display\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc104954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.env 파일 로드; 유효한 키 불러오기\n",
    "load_dotenv()\n",
    "# load_dotenv(dotenv_path=\"./env/.env\")\n",
    "print(os.getenv(\"GOOGLE_API_KEY_HW\"))\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY_HW\")\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    print(f\"Key Loaded: {GOOGLE_API_KEY[:5]}...\")\n",
    "else:\n",
    "    print(\"❌ 키를 찾을 수 없습니다. .env 파일 위치나 내용을 확인하세요.\")\n",
    "\n",
    "#사용예시\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb5963",
   "metadata": {},
   "source": [
    "## Util 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1873fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(json_output):\n",
    "  # Parsing out the markdown fencing\n",
    "  lines = json_output.splitlines()\n",
    "  for i, line in enumerate(lines):\n",
    "    if line == \"```json\":\n",
    "      # Remove everything before \"```json\"\n",
    "      json_output = \"\\n\".join(lines[i + 1 :])\n",
    "      # Remove everything after the closing \"```\"\n",
    "      json_output = json_output.split(\"```\")[0]\n",
    "      break  # Exit the loop once \"```json\" is found\n",
    "  return json_output\n",
    "\n",
    "\n",
    "def get_image_resized(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(\n",
    "        (800, int(800 * img.size[1] / img.size[0])), Image.Resampling.LANCZOS\n",
    "    )\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_point_html(pil_image, points_json):\n",
    "  buffered = BytesIO()\n",
    "  pil_image.save(buffered, format=\"PNG\")\n",
    "  img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "  points_json = parse_json(points_json)\n",
    "\n",
    "  return f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Point Visualization</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background: #fff;\n",
    "            color: #000;\n",
    "            font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif;\n",
    "        }}\n",
    "\n",
    "        .point-overlay {{\n",
    "            position: absolute;\n",
    "            top: 0;\n",
    "            left: 0;\n",
    "            width: 100%;\n",
    "            height: 100%;\n",
    "            pointer-events: none;\n",
    "        }}\n",
    "\n",
    "        .point {{\n",
    "            position: absolute;\n",
    "            width: 12px;\n",
    "            height: 12px;\n",
    "            background-color: #2962FF;\n",
    "            border: 2px solid #fff;\n",
    "            border-radius: 50%;\n",
    "            transform: translate(-50%, -50%);\n",
    "            box-shadow: 0 0 40px rgba(41, 98, 255, 0.6);\n",
    "            opacity: 0;\n",
    "            transition: all 0.3s ease-in;\n",
    "            pointer-events: auto;\n",
    "        }}\n",
    "\n",
    "        .point.visible {{\n",
    "            opacity: 1;\n",
    "        }}\n",
    "\n",
    "        .point.fade-out {{\n",
    "            animation: pointFadeOut 0.3s forwards;\n",
    "        }}\n",
    "\n",
    "        .point.highlight {{\n",
    "            transform: translate(-50%, -50%) scale(1.1);\n",
    "            background-color: #FF4081;\n",
    "            box-shadow: 0 0 40px rgba(255, 64, 129, 0.6);\n",
    "            z-index: 100;\n",
    "        }}\n",
    "\n",
    "        @keyframes pointFadeOut {{\n",
    "            from {{\n",
    "                opacity: 1;\n",
    "            }}\n",
    "            to {{\n",
    "                opacity: 0.7;\n",
    "            }}\n",
    "        }}\n",
    "\n",
    "        .point-label {{\n",
    "            position: absolute;\n",
    "            background-color: #2962FF;\n",
    "            color: #fff;\n",
    "            font-size: 14px;\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 4px;\n",
    "            transform: translate(20px, -10px);\n",
    "            white-space: nowrap;\n",
    "            opacity: 0;\n",
    "            transition: all 0.3s ease-in;\n",
    "            box-shadow: 0 0 30px rgba(41, 98, 255, 0.4);\n",
    "            pointer-events: auto;\n",
    "            cursor: pointer;\n",
    "        }}\n",
    "\n",
    "        .point-label.visible {{\n",
    "            opacity: 1;\n",
    "        }}\n",
    "\n",
    "        .point-label.fade-out {{\n",
    "            opacity: 0.45;\n",
    "        }}\n",
    "\n",
    "        .point-label.highlight {{\n",
    "            background-color: #FF4081;\n",
    "            box-shadow: 0 0 30px rgba(255, 64, 129, 0.4);\n",
    "            transform: translate(20px, -10px) scale(1.1);\n",
    "            z-index: 100;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"container\" style=\"position: relative;\">\n",
    "        <canvas id=\"canvas\" style=\"background: #000;\"></canvas>\n",
    "        <div id=\"pointOverlay\" class=\"point-overlay\"></div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        function annotatePoints(frame) {{\n",
    "            // Add points with fade effect\n",
    "            const pointsData = {points_json};\n",
    "\n",
    "            const pointOverlay = document.getElementById(\"pointOverlay\");\n",
    "            pointOverlay.innerHTML = \"\";\n",
    "\n",
    "            const points = [];\n",
    "            const labels = [];\n",
    "\n",
    "            pointsData.forEach(pointData => {{\n",
    "                // Skip entries without coodinates.\n",
    "                if (!(pointData.hasOwnProperty(\"point\")))\n",
    "                  return;\n",
    "\n",
    "                const point = document.createElement(\"div\");\n",
    "                point.className = \"point\";\n",
    "                const [y, x] = pointData.point;\n",
    "                point.style.left = `${{x/1000.0 * 100.0}}%`;\n",
    "                point.style.top = `${{y/1000.0 * 100.0}}%`;\n",
    "\n",
    "                const pointLabel = document.createElement(\"div\");\n",
    "                pointLabel.className = \"point-label\";\n",
    "                pointLabel.textContent = pointData.label;\n",
    "                point.appendChild(pointLabel);\n",
    "\n",
    "                pointOverlay.appendChild(point);\n",
    "                points.push(point);\n",
    "                labels.push(pointLabel);\n",
    "\n",
    "                setTimeout(() => {{\n",
    "                    point.classList.add(\"visible\");\n",
    "                    pointLabel.classList.add(\"visible\");\n",
    "                }}, 0);\n",
    "\n",
    "                // Add hover effects\n",
    "                const handleMouseEnter = () => {{\n",
    "                    // Highlight current point and label\n",
    "                    point.classList.add(\"highlight\");\n",
    "                    pointLabel.classList.add(\"highlight\");\n",
    "\n",
    "                    // Fade out other points and labels\n",
    "                    points.forEach((p, idx) => {{\n",
    "                        if (p !== point) {{\n",
    "                            p.classList.add(\"fade-out\");\n",
    "                            labels[idx].classList.add(\"fade-out\");\n",
    "                        }}\n",
    "                    }});\n",
    "                }};\n",
    "\n",
    "                const handleMouseLeave = () => {{\n",
    "                    // Remove highlight from current point and label\n",
    "                    point.classList.remove(\"highlight\");\n",
    "                    pointLabel.classList.remove(\"highlight\");\n",
    "\n",
    "                    // Restore other points and labels\n",
    "                    points.forEach((p, idx) => {{\n",
    "                        p.classList.remove(\"fade-out\");\n",
    "                        labels[idx].classList.remove(\"fade-out\");\n",
    "                    }});\n",
    "                }};\n",
    "\n",
    "                point.addEventListener(\"mouseenter\", handleMouseEnter);\n",
    "                point.addEventListener(\"mouseleave\", handleMouseLeave);\n",
    "                pointLabel.addEventListener(\"mouseenter\", handleMouseEnter);\n",
    "                pointLabel.addEventListener(\"mouseleave\", handleMouseLeave);\n",
    "            }});\n",
    "        }}\n",
    "\n",
    "        // Initialize canvas\n",
    "        const canvas = document.getElementById(\"canvas\");\n",
    "        const ctx = canvas.getContext(\"2d\");\n",
    "        const container = document.getElementById(\"container\");\n",
    "\n",
    "        // Load and draw the image\n",
    "        const img = new Image();\n",
    "        img.onload = () => {{\n",
    "            const aspectRatio = img.height / img.width;\n",
    "            canvas.width = 800;\n",
    "            canvas.height = Math.round(800 * aspectRatio);\n",
    "            container.style.width = canvas.width + \"px\";\n",
    "            container.style.height = canvas.height + \"px\";\n",
    "\n",
    "            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);\n",
    "\n",
    "            frame.width = canvas.width;\n",
    "            frame.height = canvas.height;\n",
    "            annotatePoints(frame);\n",
    "        }};\n",
    "        img.src = \"data:image/png;base64,{img_str}\";\n",
    "\n",
    "        const frame = {{\n",
    "            width: canvas.width,\n",
    "            height: canvas.height\n",
    "        }};\n",
    "\n",
    "        annotatePoints(frame);\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "additional_colors = [\n",
    "    colorname for (colorname, colorcode) in ImageColor.colormap.items()\n",
    "]\n",
    "\n",
    "\n",
    "def plot_bounding_boxes(img, bounding_boxes):\n",
    "  \"\"\"Plots bounding boxes on an image.\n",
    "\n",
    "  Plots bounding boxes on an image with markers for each a name, using PIL,\n",
    "  normalized coordinates, and different colors.\n",
    "\n",
    "  Args:\n",
    "      img_path: The path to the image file.\n",
    "      bounding_boxes: A list of bounding boxes containing the name of the object\n",
    "        and their positions in normalized [y1 x1 y2 x2] format.\n",
    "  \"\"\"\n",
    "\n",
    "  # Load the image\n",
    "  width, height = img.size\n",
    "  print(img.size)\n",
    "  # Create a drawing object\n",
    "  draw = ImageDraw.Draw(img)\n",
    "\n",
    "  # Define a list of colors\n",
    "  colors = [\n",
    "      \"red\",\n",
    "      \"green\",\n",
    "      \"blue\",\n",
    "      \"yellow\",\n",
    "      \"orange\",\n",
    "      \"pink\",\n",
    "      \"purple\",\n",
    "      \"brown\",\n",
    "      \"gray\",\n",
    "      \"beige\",\n",
    "      \"turquoise\",\n",
    "      \"cyan\",\n",
    "      \"magenta\",\n",
    "      \"lime\",\n",
    "      \"navy\",\n",
    "      \"maroon\",\n",
    "      \"teal\",\n",
    "      \"olive\",\n",
    "      \"coral\",\n",
    "      \"lavender\",\n",
    "      \"violet\",\n",
    "      \"gold\",\n",
    "      \"silver\",\n",
    "  ] + additional_colors\n",
    "\n",
    "  # Parsing out the markdown fencing\n",
    "  bounding_boxes = parse_json(bounding_boxes)\n",
    "\n",
    "#   font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=14) #수정_260117\n",
    "  try:\n",
    "    font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=14)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # Iterate over the bounding boxes\n",
    "  for i, bounding_box in enumerate(json.loads(bounding_boxes)):\n",
    "    # Select a color from the list\n",
    "    color = colors[i % len(colors)]\n",
    "\n",
    "    # Convert normalized coordinates to absolute coordinates\n",
    "    abs_y1 = int(bounding_box[\"box_2d\"][0] / 1000 * height)\n",
    "    abs_x1 = int(bounding_box[\"box_2d\"][1] / 1000 * width)\n",
    "    abs_y2 = int(bounding_box[\"box_2d\"][2] / 1000 * height)\n",
    "    abs_x2 = int(bounding_box[\"box_2d\"][3] / 1000 * width)\n",
    "\n",
    "    if abs_x1 > abs_x2:\n",
    "      abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "    if abs_y1 > abs_y2:\n",
    "      abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "    # Draw the bounding box\n",
    "    draw.rectangle(((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4)\n",
    "\n",
    "    # Draw the text\n",
    "    if \"label\" in bounding_box:\n",
    "      draw.text(\n",
    "          (abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill=color, font=font\n",
    "      )\n",
    "\n",
    "  # Display the image\n",
    "  img.show()\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class SegmentationMask:\n",
    "  # bounding box pixel coordinates (not normalized)\n",
    "  y0: int  # in [0..height - 1]\n",
    "  x0: int  # in [0..width - 1]\n",
    "  y1: int  # in [0..height - 1]\n",
    "  x1: int  # in [0..width - 1]\n",
    "  mask: np.array  # [img_height, img_width] with values 0..255\n",
    "  label: str\n",
    "\n",
    "\n",
    "def parse_segmentation_masks(\n",
    "    predicted_str: str, *, img_height: int, img_width: int\n",
    ") -> list[SegmentationMask]:\n",
    "  items = json.loads(parse_json(predicted_str))\n",
    "  masks = []\n",
    "  for item in items:\n",
    "    raw_box = item[\"box_2d\"]\n",
    "    abs_y0 = int(item[\"box_2d\"][0] / 1000 * img_height)\n",
    "    abs_x0 = int(item[\"box_2d\"][1] / 1000 * img_width)\n",
    "    abs_y1 = int(item[\"box_2d\"][2] / 1000 * img_height)\n",
    "    abs_x1 = int(item[\"box_2d\"][3] / 1000 * img_width)\n",
    "    if abs_y0 >= abs_y1 or abs_x0 >= abs_x1:\n",
    "      print(\"Invalid bounding box\", item[\"box_2d\"])\n",
    "      continue\n",
    "    label = item[\"label\"]\n",
    "    png_str = item[\"mask\"]\n",
    "    if not png_str.startswith(\"data:image/png;base64,\"):\n",
    "      print(\"Invalid mask\")\n",
    "      continue\n",
    "    png_str = png_str.removeprefix(\"data:image/png;base64,\")\n",
    "    png_str = base64.b64decode(png_str)\n",
    "    mask = Image.open(BytesIO(png_str))\n",
    "    bbox_height = abs_y1 - abs_y0\n",
    "    bbox_width = abs_x1 - abs_x0\n",
    "    if bbox_height < 1 or bbox_width < 1:\n",
    "      print(\"Invalid bounding box\")\n",
    "      continue\n",
    "    mask = mask.resize(\n",
    "        (bbox_width, bbox_height), resample=Image.Resampling.BILINEAR\n",
    "    )\n",
    "    np_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "    np_mask[abs_y0:abs_y1, abs_x0:abs_x1] = mask\n",
    "    masks.append(\n",
    "        SegmentationMask(abs_y0, abs_x0, abs_y1, abs_x1, np_mask, label)\n",
    "    )\n",
    "  return masks\n",
    "\n",
    "\n",
    "def overlay_mask_on_img(\n",
    "    img: Image, mask: np.ndarray, color: str, alpha: float = 0.7\n",
    ") -> Image.Image:\n",
    "  \"\"\"Overlays a single mask onto a PIL Image using a named color.\n",
    "\n",
    "  The mask image defines the area to be colored. Non-zero pixels in the\n",
    "  mask image are considered part of the area to overlay.\n",
    "\n",
    "  Args:\n",
    "      img: The base PIL Image object.\n",
    "      mask: A PIL Image object representing the mask. Should have the same\n",
    "        height and width as the img. Modes '1' (binary) or 'L' (grayscale) are\n",
    "        typical, where non-zero pixels indicate the masked area.\n",
    "      color: A standard color name string (e.g., 'red', 'blue', 'yellow').\n",
    "      alpha: The alpha transparency level for the overlay (0.0 fully\n",
    "        transparent, 1.0 fully opaque). Default is 0.7 (70%).\n",
    "\n",
    "  Returns:\n",
    "      A new PIL Image object (in RGBA mode) with the mask overlaid.\n",
    "\n",
    "  Raises:\n",
    "      ValueError: If color name is invalid, mask dimensions mismatch img\n",
    "                  dimensions, or alpha is outside the 0.0-1.0 range.\n",
    "  \"\"\"\n",
    "  if not (0.0 <= alpha <= 1.0):\n",
    "    raise ValueError(\"Alpha must be between 0.0 and 1.0\")\n",
    "\n",
    "  # Convert the color name string to an RGB tuple\n",
    "  try:\n",
    "    color_rgb: Tuple[int, int, int] = ImageColor.getrgb(color)\n",
    "  except ValueError as e:\n",
    "    # Re-raise with a more informative message if color name is invalid\n",
    "    raise ValueError(\n",
    "        f\"Invalid color name '{color}'. Supported names are typically HTML/CSS \"\n",
    "        f\"color names. Error: {e}\"\n",
    "    )\n",
    "\n",
    "  # Prepare the base image for alpha compositing\n",
    "  img_rgba = img.convert(\"RGBA\")\n",
    "  width, height = img_rgba.size\n",
    "\n",
    "  # Create the colored overlay layer\n",
    "  # Calculate the RGBA tuple for the overlay color\n",
    "  alpha_int = int(alpha * 255)\n",
    "  overlay_color_rgba = color_rgb + (alpha_int,)\n",
    "\n",
    "  # Create an RGBA layer (all zeros = transparent black)\n",
    "  colored_mask_layer_np = np.zeros((height, width, 4), dtype=np.uint8)\n",
    "\n",
    "  # Mask has values between 0 and 255, threshold at 127 to get binary mask.\n",
    "  mask_np_logical = mask > 127\n",
    "\n",
    "  # Apply the overlay color RGBA tuple where the mask is True\n",
    "  colored_mask_layer_np[mask_np_logical] = overlay_color_rgba\n",
    "\n",
    "  # Convert the NumPy layer back to a PIL Image\n",
    "  colored_mask_layer_pil = Image.fromarray(colored_mask_layer_np, \"RGBA\")\n",
    "\n",
    "  # Composite the colored mask layer onto the base image\n",
    "  result_img = Image.alpha_composite(img_rgba, colored_mask_layer_pil)\n",
    "\n",
    "  return result_img\n",
    "\n",
    "\n",
    "def plot_segmentation_masks(\n",
    "    img: Image, segmentation_masks: list[SegmentationMask]\n",
    "):\n",
    "  \"\"\"Plots bounding boxes on an image.\n",
    "\n",
    "  Plots bounding boxes on an image with markers for each a name, using PIL,\n",
    "  normalized coordinates, and different colors.\n",
    "\n",
    "  Args:\n",
    "      img: The PIL.Image.\n",
    "      segmentation_masks: A string encoding as JSON a list of segmentation masks\n",
    "        containing the name of the object, their positions in normalized [y1 x1\n",
    "        y2 x2] format, and the png encoded segmentation mask.\n",
    "  \"\"\"\n",
    "  # Define a list of colors\n",
    "  colors = [\n",
    "      \"red\",\n",
    "      \"green\",\n",
    "      \"blue\",\n",
    "      \"yellow\",\n",
    "      \"orange\",\n",
    "      \"pink\",\n",
    "      \"purple\",\n",
    "      \"brown\",\n",
    "      \"gray\",\n",
    "      \"beige\",\n",
    "      \"turquoise\",\n",
    "      \"cyan\",\n",
    "      \"magenta\",\n",
    "      \"lime\",\n",
    "      \"navy\",\n",
    "      \"maroon\",\n",
    "      \"teal\",\n",
    "      \"olive\",\n",
    "      \"coral\",\n",
    "      \"lavender\",\n",
    "      \"violet\",\n",
    "      \"gold\",\n",
    "      \"silver\",\n",
    "  ] + additional_colors\n",
    "\n",
    "  font = ImageFont.load_default()\n",
    "\n",
    "  # Do this in 3 passes to make sure the boxes and text are always visible.\n",
    "\n",
    "  # Overlay the mask\n",
    "  for i, mask in enumerate(segmentation_masks):\n",
    "    color = colors[i % len(colors)]\n",
    "    img = overlay_mask_on_img(img, mask.mask, color)\n",
    "\n",
    "  # Create a drawing object\n",
    "  draw = ImageDraw.Draw(img)\n",
    "\n",
    "  # Draw the bounding boxes\n",
    "  for i, mask in enumerate(segmentation_masks):\n",
    "    color = colors[i % len(colors)]\n",
    "    draw.rectangle(\n",
    "        ((mask.x0, mask.y0), (mask.x1, mask.y1)), outline=color, width=4\n",
    "    )\n",
    "\n",
    "  # Draw the text labels\n",
    "  for i, mask in enumerate(segmentation_masks):\n",
    "    color = colors[i % len(colors)]\n",
    "    if mask.label != \"\":\n",
    "      draw.text((mask.x0 + 8, mask.y0 - 20), mask.label, fill=color, font=font)\n",
    "  return img\n",
    "\n",
    "\n",
    "def overlay_points_on_frames(original_frames, points_data_per_frame):\n",
    "  \"\"\"Overlays points on original frames and returns the modified frames.\"\"\"\n",
    "  modified_frames = []\n",
    "\n",
    "  # Define colors for drawing points (using a consistent color per label for clarity)\n",
    "  label_colors = {}\n",
    "  current_color_index = 0\n",
    "  available_colors = [\n",
    "      \"red\",\n",
    "      \"green\",\n",
    "      \"blue\",\n",
    "      \"yellow\",\n",
    "      \"orange\",\n",
    "      \"pink\",\n",
    "      \"purple\",\n",
    "      \"brown\",\n",
    "      \"gray\",\n",
    "      \"beige\",\n",
    "      \"turquoise\",\n",
    "      \"cyan\",\n",
    "      \"magenta\",\n",
    "      \"lime\",\n",
    "      \"navy\",\n",
    "      \"maroon\",\n",
    "      \"teal\",\n",
    "      \"olive\",\n",
    "      \"coral\",\n",
    "      \"lavender\",\n",
    "      \"violet\",\n",
    "      \"gold\",\n",
    "      \"silver\",\n",
    "  ]\n",
    "\n",
    "  font = ImageFont.load_default()\n",
    "\n",
    "  # Check if the number of original frames matches the number of processed data entries\n",
    "  if len(original_frames) != len(points_data_per_frame):\n",
    "    print(\n",
    "        f\"Error: Number of original frames ({len(original_frames)}) does not \"\n",
    "        \"match the number of processed point data entries\"\n",
    "        f\" ({len(points_data_per_frame)}). Cannot overlay points accurately.\"\n",
    "    )\n",
    "    return original_frames  # Return original frames if data doesn't match\n",
    "  else:\n",
    "    # Iterate through the frames and draw points\n",
    "    for i, frame_pil in enumerate(original_frames):\n",
    "      # Ensure frame is in RGB mode for drawing\n",
    "      img = frame_pil.convert(\"RGB\")\n",
    "      draw = ImageDraw.Draw(img)\n",
    "      width, height = img.size\n",
    "\n",
    "      frame_points = points_data_per_frame[i]\n",
    "\n",
    "      # Draw points on the frame\n",
    "      for point_info in frame_points:\n",
    "        if \"point\" in point_info and \"label\" in point_info:\n",
    "          y_norm, x_norm = point_info[\"point\"]\n",
    "          label = point_info[\"label\"]\n",
    "\n",
    "          # Get color for the label\n",
    "          if label not in label_colors:\n",
    "            label_colors[label] = available_colors[\n",
    "                current_color_index % len(available_colors)\n",
    "            ]\n",
    "            current_color_index += 1\n",
    "          color = label_colors[label]\n",
    "\n",
    "          # Convert normalized coordinates to absolute pixel coordinates\n",
    "          abs_x = int(x_norm / 1000.0 * width)\n",
    "          abs_y = int(y_norm / 1000.0 * height)\n",
    "\n",
    "          # Draw a circle at the point\n",
    "          point_radius = 5\n",
    "          draw.ellipse(\n",
    "              (\n",
    "                  abs_x - point_radius,\n",
    "                  abs_y - point_radius,\n",
    "                  abs_x + point_radius,\n",
    "                  abs_y + point_radius,\n",
    "              ),\n",
    "              fill=color,\n",
    "              outline=color,\n",
    "          )\n",
    "\n",
    "          # Draw the label\n",
    "          # Adjust label position to avoid going out of bounds\n",
    "          label_pos_x = abs_x + point_radius + 2\n",
    "          label_pos_y = (\n",
    "              abs_y - point_radius - 10\n",
    "              if abs_y - point_radius - 10 > 0\n",
    "              else abs_y + point_radius + 2\n",
    "          )\n",
    "          draw.text((label_pos_x, label_pos_y), label, fill=color, font=font)\n",
    "\n",
    "      # Append the modified PIL Image\n",
    "      modified_frames.append(img)\n",
    "\n",
    "    print(f\"Processed and drew points on {len(modified_frames)} frames.\")\n",
    "    return modified_frames\n",
    "\n",
    "\n",
    "def display_gif(frames_to_display):\n",
    "  \"\"\"Saves and displays a list of PIL Images as a GIF.\"\"\"\n",
    "  if frames_to_display:\n",
    "    try:\n",
    "      # Save the modified frames as a new GIF\n",
    "      # output_gif_path = \"/tmp/annotated_aloha_pen.gif\" #수정_260117\n",
    "      os.makedirs(\"output\", exist_ok=True) # 폴더 없으면 만들기 (에러 방지)\n",
    "      output_gif_path = \"output/annotated_aloha_pen.gif\"\n",
    "      # Duration per frame in milliseconds (adjust as needed, 40ms is 25fps)\n",
    "      duration_ms = 40\n",
    "      # Ensure all frames are in RGB mode before saving as GIF\n",
    "      rgb_frames = [frame.convert(\"RGB\") for frame in frames_to_display]\n",
    "      if rgb_frames:\n",
    "        rgb_frames[0].save(\n",
    "            output_gif_path,\n",
    "            save_all=True,\n",
    "            append_images=rgb_frames[1:],\n",
    "            duration=duration_ms,\n",
    "            loop=0,\n",
    "        )\n",
    "\n",
    "        # Display the GIF in Colab\n",
    "        display.display(display.Image(output_gif_path))\n",
    "        print(f\"Displayed annotated GIF: {output_gif_path}\")\n",
    "      else:\n",
    "        print(\"No frames to create GIF.\")\n",
    "\n",
    "    except Exception as e:\n",
    "      print(f\"Error creating or displaying annotated GIF: {e}\")\n",
    "  else:\n",
    "    print(\"No frames to display.\")\n",
    "\n",
    "\n",
    "def extract_frames(gif):\n",
    "  \"\"\"Extracts frames from a GIF and returns a list of PIL Image objects.\"\"\"\n",
    "  frames = []\n",
    "  try:\n",
    "    while True:\n",
    "      # Convert each frame to RGB to ensure compatibility with drawing\n",
    "      frame = gif.convert(\"RGB\")\n",
    "      frames.append(frame)\n",
    "      gif.seek(gif.tell() + 1)  # Move to the next frame\n",
    "  except EOFError:\n",
    "    pass  # End of sequence\n",
    "\n",
    "  print(f\"Extracted {len(frames)} frames from the GIF.\")\n",
    "\n",
    "  return frames\n",
    "\n",
    "\n",
    "def populate_points_for_all_frames(total_frames, step, analyzed_data):\n",
    "  \"\"\"Populates point data for all frames based on analyzed frames.\"\"\"\n",
    "  points_data_all_frames = []\n",
    "  analyzed_data_index = 0\n",
    "  for i in range(total_frames):\n",
    "    if i % step == 0 and analyzed_data_index < len(analyzed_data):\n",
    "      points_data_all_frames.append(analyzed_data[analyzed_data_index])\n",
    "      analyzed_data_index += 1\n",
    "    else:\n",
    "      # For frames that were not analyzed, use the data from the last analyzed\n",
    "      # frame or append an empty list if no frame has been analyzed yet\n",
    "      if analyzed_data_index > 0:\n",
    "        points_data_all_frames.append(analyzed_data[analyzed_data_index - 1])\n",
    "      else:\n",
    "        # Should not happen if frames list is not empty\n",
    "        points_data_all_frames.append([])\n",
    "  return points_data_all_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11712e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 저장 함수 (헬퍼) ---\n",
    "def save_json(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"✅ {filename} 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. json변환 함수 --- \n",
    "def parse_gemini_json(response_obj):\n",
    "    # 1. 응답 객체에서 텍스트 추출\n",
    "    if hasattr(response_obj, 'text') and response_obj.text:\n",
    "        raw_text = response_obj.text\n",
    "    elif isinstance(response_obj, str) and response_obj:\n",
    "        raw_text = response_obj # 이미 문자열인 경우 대비\n",
    "    else:\n",
    "        print(\"⚠️ 경고: AI 응답이 비어있거나 올바른 객체가 아닙니다.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # 2. 마크다운 클렌징\n",
    "        clean_text = raw_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        # 3. 파싱 시도\n",
    "        parsed_data = json.loads(clean_text)\n",
    "        print(\"✅ JSON 파싱 성공!\")\n",
    "        return parsed_data\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ JSON 파싱 실패: 형식이 올바르지 않습니다.\\n{e}\")\n",
    "        # 디버깅을 위해 문제의 텍스트 앞부분만 출력\n",
    "        print(f\"문제가 된 텍스트(일부):\\n{clean_text[:200]}...\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac2da6",
   "metadata": {},
   "source": [
    "# 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce9aaf",
   "metadata": {},
   "source": [
    "## 워크플로우\n",
    "1. 입력 (Raw Images): 5_camera.jpg, 6_camera.jpg ↓\n",
    "2. 분석 (Perception):\n",
    "    ◦ Gemini Robotics → [y, x] 좌표 획득\n",
    "    ◦ Gemini 3 Pro → Z값, 회전각 획득 ↓\n",
    "3. 병합 (Processing): Python 코드에서 두 정보를 합침 (vr JSON 생성) ↓\n",
    "4. 전송 및 생성 (Action):\n",
    "    ◦ VR 서버로 전송: 이 JSON을 그대로 쏘면 VR 엔진이 주사위를 배치합니다.\n",
    "    ◦ GLB 생성: 이 JSON을 generate_glb.py에 넣으면 3D 모델 파일이 만들어집니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0145e6f9",
   "metadata": {},
   "source": [
    "## STEP1: [y, x] 좌표 획득\n",
    "Robotics (Top): Red_Dice가 2개 감지됨 -> X 좌표가 작은 순서대로 Red_Dice_1, Red_Dice_2로 이름 변경."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c470736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\"point\": [529, 520], \"label\": \"White_Dice\"},\n",
      "  {\"point\": [471, 558], \"label\": \"Red_Dice\"}\n",
      "]\n",
      "```\n",
      "\n",
      "Total processing time: 1.3513 seconds\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Gemini Robotics (Top-View) \n",
    "# [y_norm, x_norm]: (세로, 가로), 0 (왼쪽/위쪽 끝) ~ 1000 (오른쪽/아래쪽 끝)\n",
    "# Allowed Colors: [\"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"White\", \"Pink\"] _260107추가\n",
    "\n",
    "img_top = Image.open(\"./input/5_camera.jpg\")\n",
    "prompt_top = textwrap.dedent(\"\"\"\n",
    "    **Task:** Detect all dice inside the blue tape area.\n",
    "    \n",
    "    **Labeling Rules:**\n",
    "    - Assign a label based on the color of the dice.\n",
    "    - Allowed Colors: [\"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"White\", \"Pink\"]\n",
    "    - Strict Format: \"{Color}_Dice\" (e.g., \"Red_Dice\", \"White_Dice\").\n",
    "    \n",
    "    **Output Format:**\n",
    "    Return a strictly valid JSON list of objects.\n",
    "    - Each item must have a \"point\" and a \"label\".\n",
    "    - \"point\": Must be in [y, x] format, normalized to 0-1000 scale.\n",
    "\n",
    "    **Example Output:**\n",
    "    [\n",
    "      {\"point\": , \"label\": \"Red_Dice\"},\n",
    "      {\"point\": , \"label\": \"Red_Dice\"},\n",
    "      {\"point\": , \"label\": \"White_Dice\"}\n",
    "    ]\n",
    "    \"\"\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "client_robo = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "json_top = client_robo.models.generate_content(\n",
    "    model=\"gemini-robotics-er-1.5-preview\",\n",
    "    contents=[\n",
    "        img_top,\n",
    "        prompt_top,\n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.5,\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0),\n",
    "    )\n",
    ")\n",
    "print(json_top.text)\n",
    "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99486e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON 파싱 성공!\n"
     ]
    }
   ],
   "source": [
    "robotics_data = []\n",
    "\n",
    "# ✅ 안전한 파싱 로직 시작\n",
    "if json_top.text:  # 1. 빈 값인지 먼저 체크\n",
    "    try:\n",
    "        # 2. 마크다운(```json) 제거 (클렌징)\n",
    "        raw_text = json_top.text\n",
    "        clean_text = raw_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        \n",
    "        robotics_data = json.loads(clean_text)\n",
    "        print(\"✅ JSON 파싱 성공!\")\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ JSON 파싱 실패: 형식이 올바르지 않습니다.\\n{e}\")\n",
    "        print(f\"문제가 된 텍스트:\\n{clean_text}\")\n",
    "else:\n",
    "    print(\"⚠️ 경고: AI 응답이 비어있습니다. (Safety Filter에 걸렸을 수 있음)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed23926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step1_robotics_raw.json 저장 완료\n"
     ]
    }
   ],
   "source": [
    "if robotics_data:\n",
    "    output_dir = \"./output/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    robotics_data_path = os.path.join(output_dir, \"50_step1_robotics_raw.json\")\n",
    "    save_json(robotics_data, robotics_data_path) # 파일로 백업 (안전장치)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031f663",
   "metadata": {},
   "source": [
    "## STEP2: Z값, 회전각 획득\n",
    "Pro (Side): 이미지에서 왼쪽부터 오른쪽으로 주사위를 읽으라고 지시 -> 순서대로 Red_Dice_1, Red_Dice_2로 매핑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fdcd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['executable_code', 'thought_signature', 'code_execution_result', 'inline_data', 'executable_code', 'thought_signature', 'code_execution_result', 'executable_code', 'thought_signature', 'inline_data', 'executable_code', 'thought_signature', 'inline_data', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the analysis of the image, there are two dice clearly visible within the designated play area (marked by the blue tape). The peripheral objects (wires, partial dice outside the tape) are excluded as they are outside the region of interest and/or partially obscured.\n",
      "\n",
      "1.  **Red Dice (Left):**\n",
      "    -   **Position:** Located on the left side of the central pair.\n",
      "    -   **Color:** Red.\n",
      "    -   **Z-Level:** Resting on the table surface, so `z_mm = 0`.\n",
      "    -   **Rotation:** The die is aligned with the camera/table axes. The top face (6 pips) shows horizontal rows, and the edges are vertical/horizontal. Estimated rotation is **0 degrees**.\n",
      "\n",
      "2.  **White Dice (Right):**\n",
      "    -   **Position:** Located on the right side of the central pair.\n",
      "    -   **Color:** White.\n",
      "    -   **Z-Level:** Resting on the table surface, so `z_mm = 0`.\n",
      "    -   **Rotation:** The die is rotated such that a corner is pointing towards the camera. The top face (3 pips) is diagonal. This orientation corresponds to a **45 degree** rotation.\n",
      "\n",
      "**Spatial Ordering:**\n",
      "-   Red Dice (Left, x ~ 937)\n",
      "-   White Dice (Right, x ~ 1021)\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"label\": \"Red_Dice\",\n",
      "    \"z_mm\": 0,\n",
      "    \"rotation\": 0\n",
      "  },\n",
      "  {\n",
      "    \"label\": \"White_Dice\",\n",
      "    \"z_mm\": 0,\n",
      "    \"rotation\": 45\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Total processing time: 126.1518 seconds\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Gemini 3 Pro (Side-View) --> 프롬프트 수정\n",
    "#일관성이 없으면: top에서 나온 데이터를 주입해서 활용하게 할 것\n",
    "\n",
    "img_high = Image.open(\"./input/6_camera.jpg\")\n",
    "\n",
    "prompt_high = textwrap.dedent(\"\"\"\\\n",
    "    **Role:** You are a 3D Spatial Analysis Agent.\n",
    "    \n",
    "    **Task:** \n",
    "    Analyze the image (Side-View) to extract 3D attributes of ALL dice visible in the scene.\n",
    "    \n",
    "    **CRITICAL ORDERING RULE (MUST FOLLOW):**\n",
    "    - You MUST output the list of objects sorted spatially from **LEFT to RIGHT** in the image.\n",
    "    - If objects are stacked vertically, list the **Bottom** object first, then the Top object.\n",
    "    \n",
    "    **Extraction Requirements:**\n",
    "    1. **Identify & Label:** \n",
    "       - Detect all dice regardless of color.\n",
    "       - Determine the color of each die dynamically (e.g., Red, Blue, Green, Yellow, etc.).\n",
    "       - **Label Format:** Strict adherence to \"{Color}_Dice\" (e.g., \"Blue_Dice\", \"Yellow_Dice\").\n",
    "       \n",
    "    2. **Z-Level:** Determine the height in millimeters. (Assume 1 dice height = 20mm).\n",
    "       - On the table: `z_mm = 0`\n",
    "       - On top of another dice: `z_mm = 20` (and so on).\n",
    "       \n",
    "    3. **Rotation:** Estimate the rotation (Yaw) in degrees relative to the camera frame.\n",
    "    \n",
    "    **Output Format:**\n",
    "    Return a strictly valid JSON list.\n",
    "    Example (Do not copy values, just the structure):\n",
    "    [\n",
    "      { \"label\": \"Blue_Dice\", \"z_mm\": 0, \"rotation\": 15 },\n",
    "      { \"label\": \"Yellow_Dice\", \"z_mm\": 20, \"rotation\": 0 }\n",
    "    ]\n",
    "    \n",
    "    \"\"\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "client_pro = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "json_high = client_pro.models.generate_content(\n",
    "    model=\"gemini-3-pro-preview\",\n",
    "    contents=[\n",
    "        img_high,\n",
    "        prompt_high,\n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.5, #수정 ->> 0.4\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=1024),\n",
    "        # tools=[types.Tool(code_execution=types.ToolCodeExecution)], #제거 ->> Gemini가 코드를 짜고 자기가 알아서 실행 \n",
    "        # response_mime_type=\"application/json\" #선택 ->> JSON 포맷 강제\n",
    "    )\n",
    ")\n",
    "print(json_high.text)\n",
    "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04e85e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['executable_code', 'thought_signature', 'code_execution_result', 'inline_data', 'executable_code', 'thought_signature', 'code_execution_result', 'executable_code', 'thought_signature', 'inline_data', 'executable_code', 'thought_signature', 'inline_data', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "Warning: there are non-text parts in the response: ['executable_code', 'thought_signature', 'code_execution_result', 'inline_data', 'executable_code', 'thought_signature', 'code_execution_result', 'executable_code', 'thought_signature', 'inline_data', 'executable_code', 'thought_signature', 'inline_data', 'thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ JSON 파싱 성공!\n",
      "[{'label': 'Red_Dice', 'z_mm': 0, 'rotation': 0}, {'label': 'White_Dice', 'z_mm': 0, 'rotation': 45}]\n"
     ]
    }
   ],
   "source": [
    "robotics_data_2 = []\n",
    "\n",
    "if json_high.text:\n",
    "    try:\n",
    "        # 2. 정규표현식으로 ```json 과 ``` 사이의 내용만 쏙 뽑아냅니다.\n",
    "        # r\"...\" : Raw String\n",
    "        # (.*?) : 괄호 안의 내용을 찾음 (Non-greedy)\n",
    "        # re.DOTALL : 줄바꿈이 있어도 찾을 수 있게 함\n",
    "        match = re.search(r\"```json(.*?)```\", json_high.text, re.DOTALL)\n",
    "        \n",
    "        if match:\n",
    "            clean_text = match.group(1).strip() # 찾은 내용만 추출\n",
    "        else:\n",
    "            # 만약 마크다운이 없다면 전체 텍스트 사용 (혹시 모를 대비)\n",
    "            clean_text = json_high.text.strip()\n",
    "        \n",
    "        # 3. 파싱 시도\n",
    "        robotics_data_2 = json.loads(clean_text)\n",
    "        print(\"✅ JSON 파싱 성공!\")\n",
    "        print(robotics_data_2) # 결과 확인\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ JSON 파싱 실패: 형식이 올바르지 않습니다.\\n{e}\")\n",
    "        print(f\"문제가 된 텍스트:\\n{clean_text}\") # 필요시 주석 해제\n",
    "else:\n",
    "    print(\"⚠️ 경고: AI 응답이 비어있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2999e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step2_pro_attributes.json 저장 완료\n"
     ]
    }
   ],
   "source": [
    "if robotics_data_2:\n",
    "    output_dir = \"./output/\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    robotics_data_2_path = os.path.join(output_dir, \"50_step2_pro_attributes.json\")\n",
    "    save_json(robotics_data_2, robotics_data_2_path) # 파일로 백업 (안전장치)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e6e41",
   "metadata": {},
   "source": [
    "## STEP3: label 기준 1차 병합\n",
    "stack_i(Unique ID) 구분: **\"Top-View의 X,Y 좌표가 겹치면(Threshold) 같은 ID를 부여하고, 높이(Level) 순서는 Side-View를 본 Gemini에게 물어보는 것\"**입니다. 이것이 물리적 좌표의 정확성와 시각적 추론의 유연성을 모두 잡는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "057aa365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Python 병합 (Merging)\n",
    "\n",
    "# 파이썬 병합 코드 (1:N 매칭 지원)\n",
    "# 이 코드는 Top-View의 좌표를 Side-View의 층수(Level)만큼 복제(Duplicate)하여 병합합니다.\n",
    "\n",
    "def merge_stacked_dice(robotics_data, pro_data):\n",
    "    merged_list = []\n",
    "    \n",
    "    # 1. Pro 데이터를 색상별로 그룹화 (Stacking 감지)\n",
    "    # 예: pro_groups = {'Red_Dice': [obj1, obj2], 'White_Dice': [obj3]}\n",
    "    pro_groups = {}\n",
    "    for item in pro_data:\n",
    "        label = item['label']\n",
    "        if label not in pro_groups:\n",
    "            pro_groups[label] = []\n",
    "        pro_groups[label].append(item)\n",
    "\n",
    "    # 2. Robotics(좌표) 데이터를 순회하며 매칭\n",
    "    # 좌표 정렬: 왼쪽(X) -> 오른쪽\n",
    "    robotics_sorted = sorted(robotics_data, key=lambda k: k['point'][1]) # [y, x]이므로 index 1이 x\n",
    "\n",
    "    # 색상별로 Robotics에서 몇 번째 주사위인지 카운트\n",
    "    robotics_counters = {} \n",
    "\n",
    "    for robo_item in robotics_sorted:\n",
    "        color_label = robo_item['label']\n",
    "        point = robo_item['point'] # \n",
    "        \n",
    "        # 현재 색상의 주사위가 Pro 데이터에 있는지 확인\n",
    "        if color_label in pro_groups:\n",
    "            # Pro에서 해당 색상의 리스트를 가져옴\n",
    "            target_list = pro_groups[color_label]\n",
    "            \n",
    "            # [핵심 로직] Robotics는 1개인데 Pro는 여러 개일 경우 (쌓인 상태)\n",
    "            # Robotics의 좌표 하나를 Pro의 모든 항목에 적용해야 함\n",
    "            \n",
    "            # 여기서 단순 매칭이 아니라, \"아직 좌표를 할당받지 못한\" Pro 아이템들을 찾아서 할당\n",
    "            # (이 예제에서는 Red_Dice 1개 vs 2개 상황을 가정하여 단순화함)\n",
    "            \n",
    "            # 만약 Robotics도 Red가 2개고 Pro도 2개면? -> 순서대로 매칭 (기존 로직)\n",
    "            # 만약 Robotics는 1개인데 Pro가 2개면? -> 둘 다 이 좌표를 씀 (스택)\n",
    "            \n",
    "            # 스택 판별: 해당 X좌표 근처에 있는 Pro 그룹을 몽땅 가져와야 함.\n",
    "            # 하지만 더 쉬운 방법: Pro 데이터에 이미 'stack_id'나 순서가 있다면 그것을 따름.\n",
    "            # 여기서는 사용자 데이터에 stack_id가 없으므로 \"개수 차이\"를 이용해 복제합니다.\n",
    "            \n",
    "            # 간단한 전략: Robotics에서 Red가 1개 나왔는데 Pro에 Red가 2개 있다면,\n",
    "            # Pro의 Red 2개 모두에게 이 Robotics 좌표를 부여함.\n",
    "            \n",
    "            # (주의: 만약 옆에 또다른 Red 스택이 있다면 이 로직은 정교해져야 함.\n",
    "            # X좌표 클러스터링이 가장 정확하지만, 지금은 리스트 순서대로 소진(Consume)하는 방식 사용)\n",
    "            \n",
    "            num_pro = len(target_list)\n",
    "            # Robotics 데이터가 N개라고 가정할 때, 현재 처리 중인 순서에 맞는 Pro 데이터를 가져와야 함.\n",
    "            # 이 부분은 복잡하므로, 질문하신 상황(1 vs 2)에 특화된 로직:\n",
    "            \n",
    "            # Pro 리스트에서 앞에서부터(Pop) 꺼내서 매칭하되,\n",
    "            # 만약 Pro 리스트가 Robotics 리스트보다 길다면? -> 같은 좌표를 계속 씀? (X)\n",
    "            # Pro의 z_mm를 보고 판단합니다.\n",
    "            \n",
    "            # 가장 현실적인 해결책: Pro 데이터를 다 돌면서 Robotics의 가장 가까운 좌표를 찾는다. (X)\n",
    "            # 역발상: Robotics 데이터를 기준으로 Pro 데이터를 '할당'한다.\n",
    "            pass \n",
    "\n",
    "    # --- 실전 해결 코드 (간소화 버전) ---\n",
    "    # Pro 데이터를 메인으로 잡고, Robotics 좌표를 참조(Lookup)하는 방식이 낫습니다.\n",
    "    \n",
    "    # 1. Robotics 데이터를 색상별 큐(Queue)로 만듦\n",
    "    # {'Red_Dice': [coord1], 'White_Dice': [coord2]}\n",
    "    robo_queues = {}\n",
    "    for item in sorted(robotics_data, key=lambda k: k['point'][1]):\n",
    "        lbl = item['label']\n",
    "        if lbl not in robo_queues: robo_queues[lbl] = []\n",
    "        robo_queues[lbl].append(item['point'])\n",
    "        \n",
    "    # 2. Pro 데이터를 순회하며 좌표 할당\n",
    "    final_objects = []\n",
    "    \n",
    "    # Pro 데이터도 왼쪽->오른쪽 순서라고 가정 (프롬프트에서 제어함)\n",
    "    # 하지만 쌓여있으면(Red 2개), Robotics 큐에는 Red 좌표가 1개뿐임.\n",
    "    # 따라서 \"Pop\" 하지 말고, \"Peep(살펴보기)\" 하다가 새로운 스택(옆 주사위)으로 넘어갈 때만 Pop 해야 함.\n",
    "    \n",
    "    # 그러나 이것을 자동화하기엔 복잡하므로, 가장 쉬운 룰:\n",
    "    # \"같은 색상이 연속으로 나오면(z값 차이), 같은 좌표를 쓴다.\"\n",
    "    \n",
    "    last_label = None\n",
    "    last_coord = None\n",
    "    label_counters = {} #추가_260107\n",
    "    \n",
    "    for pro_item in pro_data:\n",
    "        label = pro_item['label']\n",
    "        z_mm = pro_item.get('z_mm', 0)\n",
    "        \n",
    "        # 좌표 가져오기 로직\n",
    "        current_coord = None\n",
    "        \n",
    "        if label in robo_queues and robo_queues[label]:\n",
    "            # 스택 감지: 같은 색상이고 Z가 0보다 크면(즉 2층이면), 방금 썼던 좌표 재사용\n",
    "            if z_mm > 0 and last_label == label and last_coord is not None:\n",
    "                 current_coord = last_coord\n",
    "            else:\n",
    "                # 1층이거나 새로운 주사위면 큐에서 하나 꺼냄 (없으면 1층 좌표 재사용하거나 예외처리)\n",
    "                if robo_queues[label]:\n",
    "                    current_coord = robo_queues[label] # 일단 봄\n",
    "                    # 만약 이게 정말 새 스택인지 확인하려면? \n",
    "                    # 사용자 데이터상 Red(1층), Red(2층) 순서로 옴.\n",
    "                    # Red(1층) -> 좌표 꺼냄(Pop)\n",
    "                    # Red(2층) -> 좌표 재사용(Pop 안함)\n",
    "                    \n",
    "                    if z_mm == 0: # 새로운 바닥 주사위\n",
    "                        current_coord = robo_queues[label].pop(0) \n",
    "                    else: # 쌓인 주사위 (이전 바닥 주사위 좌표 공유)\n",
    "                        # 주의: 바로 앞이 같은 색이어야 함. \n",
    "                        # 리스트가 [Red(0), Red(20)] 순서로 정렬되어 있다고 가정\n",
    "                        current_coord = last_coord \n",
    "\n",
    "        if current_coord:\n",
    "            last_coord = current_coord\n",
    "            last_label = label\n",
    "\n",
    "            #추가_260107\n",
    "            if 'unique_id' not in pro_item:\n",
    "                count = label_counters.get(label, 0)\n",
    "                unique_id = f\"{label}_{count}\"\n",
    "                label_counters[label] = count + 1\n",
    "            else:\n",
    "                unique_id = pro_item['unique_id']\n",
    "            \n",
    "            # 병합된 객체 생성\n",
    "            new_obj = pro_item.copy()\n",
    "            new_obj['unique_id'] = unique_id #추가_260107\n",
    "            new_obj['point'] = current_coord # [y, x]\n",
    "            final_objects.append(new_obj)\n",
    "            \n",
    "    return final_objects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step3_merged_final.json 저장 완료\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./output/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "merged_data = merge_stacked_dice(robotics_data, robotics_data_2) # 변수 사용\n",
    "save_path = os.path.join(output_dir, \"50_step3_merged_final.json\")\n",
    "save_json(merged_data, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00319d3e",
   "metadata": {},
   "source": [
    "## (선택)STEP4: 이미지로 검증\n",
    "▪ 쌓여 있는 주사위 위에 점이 찍혔는데, 라벨에 Z:1(2층)이라고 적혀 있는가?\n",
    "\n",
    "▪ 살짝 돌아간 주사위 라벨에 Rot:45 등 0이 아닌 값이 적혀 있는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb15520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Step 4] 시각화 검증 (Visualization)\n",
    "# 파일에서 읽어와도 되고, merged_data 변수를 바로 넣어도 됩니다.\n",
    "# 사용자님이 제공한 overlay_points_on_frames [Source 121] 함수는 리스트 형태의 데이터를 입력받습니다. \n",
    "# 파일로 저장해두면, 나중에 시각화 함수만 따로 떼어내서(visualization_utils.py)독립적으로 테스트할 수 있어 매우 편리합니다; \n",
    "\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# [Source 121] 제공해주신 소스 코드의 함수를 그대로 가져옵니다.\n",
    "# (실제 환경에서는 import해서 쓰셔도 됩니다)\n",
    "# 0~1000 스케일의 정규화된 값을 실제 픽셀로 변환합니다.\n",
    "def overlay_points_on_frames(original_frames, points_data_per_frame):\n",
    "    # ... (소스 코드 내용 생략, 위에서 정의된 함수 사용) ...\n",
    "    # 편의를 위해 소스 코드 로직을 그대로 사용하되, 실행 가능한 형태로 아래에 통합했습니다.\n",
    "    modified_frames = []\n",
    "    # 색상 리스트 [Source 121]\n",
    "    available_colors = [\"red\", \"green\", \"blue\", \"yellow\", \"orange\", \"white\", \"pink\"]\n",
    "    label_colors = {}\n",
    "    current_color_index = 0\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for i, frame_pil in enumerate(original_frames):\n",
    "        img = frame_pil.convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        width, height = img.size\n",
    "        print(f\"이미지 크기: {width}x{height}\") # 디버깅용\n",
    "\n",
    "        frame_points = points_data_per_frame[i]\n",
    "\n",
    "        for point_info in frame_points:\n",
    "            if \"point\" in point_info and \"label\" in point_info:\n",
    "                y_norm, x_norm = point_info[\"point\"]\n",
    "                label_text = point_info[\"label\"] # 수정된 라벨(속성 포함)\n",
    "\n",
    "                # 색상 지정\n",
    "                base_label = label_text.split('\\n')[0] # 색상은 원래 이름(Red_Dice) 기준  #수정; 리스트에서 **첫 번째 요소(진짜 라벨 이름)**만 꺼내서 키로 써야 합니다.\n",
    "                if base_label not in label_colors:\n",
    "                    label_colors[base_label] = available_colors[current_color_index % len(available_colors)]\n",
    "                    current_color_index += 1\n",
    "                color = label_colors[base_label]\n",
    "\n",
    "                # [Source 124] 좌표 변환 (0-1000 -> 픽셀)\n",
    "                abs_x = int(x_norm / 1000.0 * width)\n",
    "                abs_y = int(y_norm / 1000.0 * height)\n",
    "\n",
    "                # 점 찍기\n",
    "                r = 5\n",
    "                draw.ellipse((abs_x - r, abs_y - r, abs_x + r, abs_y + r), fill=color, outline=color)\n",
    "\n",
    "                # 라벨 그리기 (위치 조정)\n",
    "                draw.text((abs_x + 8, abs_y - 10), label_text, fill=color, font=font)\n",
    "        \n",
    "        modified_frames.append(img)\n",
    "    return modified_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe43eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. 데이터 및 이미지 로드 ---\n",
    "# 병합된 최종 JSON 파일 로드\n",
    "with open(\"./output/50_step3_merged_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    merged_data = json.load(f)\n",
    "\n",
    "# Top-View 이미지 로드 [Source 1]\n",
    "image_path = \"./input/5_camera.jpg\"\n",
    "if not os.path.exists(image_path):\n",
    "    print(f\"⚠️ 경고: {image_path} 파일이 없습니다.\")\n",
    "    # 테스트용 빈 이미지 생성\n",
    "    img_top = Image.new('RGB', (1000, 1000), color='black')\n",
    "else:\n",
    "    img_top = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e79e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. 검증용 데이터 포맷팅 (Visual Formatting) ---\n",
    "# 기존 overlay 함수가 {\"point\": [y,x], \"label\": \"str\"} 형식을 받으므로 이에 맞춰 변환합니다.\n",
    "verification_data = []\n",
    "\n",
    "for item in merged_data:\n",
    "    # [핵심] 3D 속성 정보를 텍스트 라벨에 욱여넣습니다.\n",
    "    # 이렇게 하면 이미지 상에서 Z값과 회전각을 눈으로 확인할 수 있습니다.\n",
    "    debug_label = (\n",
    "        f\"{item['label']}\\n\"       # 예: Red_Dice_0\n",
    "        f\"Z: {item['z_mm']}mm\\n\"       # 예: Z: 20mm (2층 확인용)\n",
    "        f\"Rot: {item['rotation']}°\"    # 예: Rot: 45°\n",
    "    )\n",
    "    \n",
    "    # 데이터 구조 맞추기\n",
    "    verification_data.append({\n",
    "        \"point\": item['point'], # [y, x] (Source 47 포맷)\n",
    "        \"label\": debug_label,             # 화면에 출력될 텍스트\n",
    "        # \"label\": f\"{item['unique_id']}\\nZ:{item['z_mm']}\" #디버깅용_추후수정\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c584bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 크기: 1920x1080\n",
      "✅ 검증 이미지(50_step4_verify_merge.jpg)가 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# from my_utils import overlay_points_on_frames # 사용자 소스 코드 모음\n",
    "\n",
    "# --- 3. 시각화 실행 및 저장 ---\n",
    "# 함수는 리스트 형태(영상 프레임)를 받도록 설계되어 있으므로 리스트로 감싸서 전달 [Source 121]\n",
    "annotated_frames = overlay_points_on_frames([img_top], [verification_data])\n",
    "\n",
    "# 결과 확인\n",
    "result_img = annotated_frames[0]\n",
    "result_img.show()  # 화면에 띄우기\n",
    "result_img.save(\"./output/50_step4_verify_merge.jpg\") # 파일로 저장\n",
    "print(\"✅ 검증 이미지(50_step4_verify_merge.jpg)가 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb64c9e",
   "metadata": {},
   "source": [
    "## (선택)STEP4-2: AI로 역검증\n",
    "• 1, 2단계에서 만든 **'점과 글자가 찍힌 검증용 이미지'**를 다시 Gemini에게 보냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c4e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ai에게 검증시키기 X\n",
    "# Prompt: \"Here is an image annotated with AI analysis results. Please audit this image. If the label says 'Z:20' (meaning 2nd floor), distinctively verify if the object is physically stacked on top of another. Report any discrepancies between the text label and the visual reality.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ae4c3",
   "metadata": {},
   "source": [
    "## STEP5: VR용 최종 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f7731",
   "metadata": {},
   "source": [
    "'''\n",
    "최적의 VR 전송용 JSON 구조 (Recommended)\n",
    "\n",
    "VR 엔진이 추가 연산 없이 바로 객체(Actor)를 생성할 수 있도록 World Transform(위치, 회전, 스케일) 중심으로 구성된 구조입니다.\n",
    "{\n",
    "  \"timestamp\": 1716345600,  // 동기화 시점 (선택)\n",
    "  \"scene_id\": \"table_top_01\",\n",
    "  \"objects\": [\n",
    "    {\n",
    "      \"id\": \"Red_Dice_0\",         // 고유 식별자 (필수)\n",
    "      \"type\": \"dice\",             // 3D 모델 에셋 이름 (Prefabs/Dice)\n",
    "      \"properties\": {\n",
    "        \"color\": \"red\",           // 재질(Material) 변경용\n",
    "        \"stack_level\": 0          // 로직 처리용 (선택)\n",
    "      },\n",
    "      \"transform\": {\n",
    "        \"position\": { \"x\": 250.5, \"y\": 10.0, \"z\": 400.2 }, // mm 단위 월드 좌표\n",
    "        \"rotation\": { \"x\": 0, \"y\": 45.0, \"z\": 0 },         // Euler Angles (Yaw 적용)\n",
    "        \"scale\": { \"x\": 1, \"y\": 1, \"z\": 1 }                // 크기 변환 필요시\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"Red_Dice_1\",\n",
    "      \"type\": \"dice\",\n",
    "      \"properties\": { \"color\": \"red\", \"stack_level\": 1 },\n",
    "      \"transform\": {\n",
    "        \"position\": { \"x\": 250.5, \"y\": 30.0, \"z\": 400.2 }, // 2층 (y + 20mm)\n",
    "        \"rotation\": { \"x\": 0, \"y\": 45.0, \"z\": 0 },\n",
    "        \"scale\": { \"x\": 1, \"y\": 1, \"z\": 1 }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "859b7d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Step 5] VR 전송용 JSON\n",
    "# Step 3에서 병합된 데이터를 위 형식으로 변환하는 함수입니다.\n",
    "\n",
    "def format_for_vr(merged_data):\n",
    "    vr_payload = {\n",
    "        \"timestamp\": time.time(),\n",
    "        \"objects\": []\n",
    "    }\n",
    "    \n",
    "    # 설정값 (테이블 실제 크기: 예 500mm x 500mm)\n",
    "    TABLE_WIDTH_MM = 150\n",
    "    TABLE_DEPTH_MM = 150\n",
    "    DICE_HEIGHT_MM = 20 # 주사위 중심 높이 (반지름 10mm 가정)\n",
    "\n",
    "    for item in merged_data:\n",
    "        # [y, x] 0-1000 정규화 좌표 -> mm 변환\n",
    "        y_norm, x_norm = item['point']\n",
    "        \n",
    "        # Unity/Unreal 좌표계 (Y-up 기준)\n",
    "        # X: 가로, Y: 높이, Z: 깊이\n",
    "        world_x = (x_norm / 1000.0) * TABLE_WIDTH_MM\n",
    "        world_z = (y_norm / 1000.0) * TABLE_DEPTH_MM\n",
    "        \n",
    "        # 높이 계산 (바닥에서 10mm 띄움 + 층수 * 20mm)\n",
    "        # z_mm가 0(바닥)이면 중심은 10mm 높이\n",
    "        world_y = 10 + item['z_mm'] \n",
    "\n",
    "        vr_obj = {\n",
    "            \"id\": item.get('unique_id', f\"{item['label']}_{int(time.time())}\"),\n",
    "            \"type\": \"dice\",\n",
    "            \"properties\": {\n",
    "                \"color\": item['label'].split('_')[0].lower() # \"Red_Dice\" -> \"red\"\n",
    "            },\n",
    "            \"transform\": {\n",
    "                \"position\": { \"x\": round(world_x, 1), \"y\": world_y, \"z\": round(world_z, 1) },\n",
    "                \"rotation\": { \"x\": 0, \"y\": item['rotation'], \"z\": 0 },\n",
    "                \"scale\": { \"x\": 1, \"y\": 1, \"z\": 1 }\n",
    "            }\n",
    "        }\n",
    "        vr_payload[\"objects\"].append(vr_obj)\n",
    "        \n",
    "    return vr_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step5_vr.json 저장 완료\n",
      "✅ VR 데이터 저장 완료: /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step5_vr.json\n"
     ]
    }
   ],
   "source": [
    "json_merged = \"./output/50_step3_merged_final.json\"\n",
    "with open(json_merged, \"r\", encoding=\"utf-8\") as f:\n",
    "    merged_data_source = json.load(f)\n",
    "vr_result = format_for_vr(merged_data_source) \n",
    "\n",
    "output_dir = \"./output/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "save_path = os.path.join(output_dir, \"50_step5_vr.json\")\n",
    "save_json(vr_result, save_path)\n",
    "\n",
    "print(f\"✅ VR 데이터 저장 완료: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5130da03",
   "metadata": {},
   "source": [
    "# 위 JSON결과물; **VR서버 전달** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28862466",
   "metadata": {},
   "source": [
    "## STEP6 -> glb생성 위한 준비; 처음 한번만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the robust Python script using `trimesh` and `numpy`.\n",
      "\n",
      "### Prerequisites\n",
      "You will need the `trimesh` library. If you haven't installed it yet:\n",
      "```bash\n",
      "pip install trimesh numpy scipy\n",
      "```\n",
      "\n",
      "### Python Script\n",
      "\n",
      "```python\n",
      "import trimesh\n",
      "import numpy as np\n",
      "import json\n",
      "import os\n",
      "\n",
      "# Configuration\n",
      "INPUT_FILENAME = 'dice_data.json'\n",
      "OUTPUT_PATH = '/Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/5_GenCode/dice_digital_twin.glb'\n",
      "\n",
      "# ---------------------------------------------------------\n",
      "# HELPER: Create the dummy JSON file for this test execution\n",
      "# (In production, this file would already exist)\n",
      "# ---------------------------------------------------------\n",
      "def create_sample_data_file():\n",
      "    data = {\n",
      "        \"timestamp\": 1770550262.377944, \n",
      "        \"objects\": [\n",
      "            {\n",
      "                \"id\": \"Red_Dice_0\", \n",
      "                \"type\": \"dice\", \n",
      "                \"properties\": {\"color\": \"red\"}, \n",
      "                \"transform\": {\n",
      "                    \"position\": {\"x\": 83.7, \"y\": 10, \"z\": 70.6}, \n",
      "                    \"rotation\": {\"x\": 0, \"y\": 0, \"z\": 0}, \n",
      "                    \"scale\": {\"x\": 1, \"y\": 1, \"z\": 1}\n",
      "                }\n",
      "            }, \n",
      "            {\n",
      "                \"id\": \"White_Dice_0\", \n",
      "                \"type\": \"dice\", \n",
      "                \"properties\": {\"color\": \"white\"}, \n",
      "                \"transform\": {\n",
      "                    \"position\": {\"x\": 78.0, \"y\": 10, \"z\": 79.4}, \n",
      "                    \"rotation\": {\"x\": 0, \"y\": 45, \"z\": 0}, \n",
      "                    \"scale\": {\"x\": 1, \"y\": 1, \"z\": 1}\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "    \n",
      "    with open(INPUT_FILENAME, 'w') as f:\n",
      "        json.dump(data, f, indent=4)\n",
      "    print(f\"DEBUG: Created temporary input file: {INPUT_FILENAME}\")\n",
      "\n",
      "# ---------------------------------------------------------\n",
      "# MAIN LOGIC\n",
      "# ---------------------------------------------------------\n",
      "\n",
      "def get_color_rgba(color_name):\n",
      "    \"\"\"Maps string color names to RGBA 0-255 values.\"\"\"\n",
      "    cmap = {\n",
      "        'red':   [255, 0, 0, 255],\n",
      "        'white': [240, 240, 240, 255], # Slightly off-white for better visibility\n",
      "        'blue':  [0, 0, 255, 255],\n",
      "        'green': [0, 255, 0, 255],\n",
      "        'black': [20, 20, 20, 255]\n",
      "    }\n",
      "    return cmap.get(color_name.lower(), [128, 128, 128, 255]) # Default gray\n",
      "\n",
      "def process_dice_twin(json_input_path, glb_output_path):\n",
      "    # 1. Dynamic Loading: Read from external JSON file\n",
      "    if not os.path.exists(json_input_path):\n",
      "        raise FileNotFoundError(f\"Input file not found: {json_input_path}\")\n",
      "        \n",
      "    with open(json_input_path, 'r') as f:\n",
      "        data = json.load(f)\n",
      "\n",
      "    # Initialize Scene\n",
      "    scene = trimesh.Scene()\n",
      "    \n",
      "    # 2. Iterate through objects\n",
      "    objects = data.get('objects', [])\n",
      "    print(f\"Processing {len(objects)} objects...\")\n",
      "\n",
      "    for obj in objects:\n",
      "        obj_id = obj.get('id', 'unknown')\n",
      "        props = obj.get('properties', {})\n",
      "        trans = obj.get('transform', {})\n",
      "        \n",
      "        # Geometry Creation\n",
      "        # We assume 'dice' is a cube. Let's give it a base size.\n",
      "        # Since positions are around ~80 units, a size of 4.0 ensures visibility.\n",
      "        mesh = trimesh.creation.box(extents=[4.0, 4.0, 4.0])\n",
      "        \n",
      "        # Apply Color\n",
      "        color_name = props.get('color', 'gray')\n",
      "        rgba = get_color_rgba(color_name)\n",
      "        mesh.visual.face_colors = rgba\n",
      "        \n",
      "        # -------------------------------------------------\n",
      "        # Transform Logic\n",
      "        # -------------------------------------------------\n",
      "        \n",
      "        # Position\n",
      "        pos_data = trans.get('position', {'x': 0, 'y': 0, 'z': 0})\n",
      "        translation = [pos_data['x'], pos_data['y'], pos_data['z']]\n",
      "        \n",
      "        # Rotation (Euler Degrees -> Radians -> Matrix)\n",
      "        rot_data = trans.get('rotation', {'x': 0, 'y': 0, 'z': 0})\n",
      "        # Converting degrees to radians\n",
      "        euler_angles = np.radians([rot_data['x'], rot_data['y'], rot_data['z']])\n",
      "        # Create rotation matrix (Assuming standard XYZ order)\n",
      "        matrix_rot = trimesh.transformations.euler_matrix(\n",
      "            euler_angles[0], euler_angles[1], euler_angles[2], axes='sxyz'\n",
      "        )\n",
      "        \n",
      "        # Scale\n",
      "        scale_data = trans.get('scale', {'x': 1, 'y': 1, 'z': 1})\n",
      "        matrix_scale = np.eye(4)\n",
      "        matrix_scale[0,0] = scale_data['x']\n",
      "        matrix_scale[1,1] = scale_data['y']\n",
      "        matrix_scale[2,2] = scale_data['z']\n",
      "        \n",
      "        # Translation Matrix\n",
      "        matrix_trans = trimesh.transformations.translation_matrix(translation)\n",
      "        \n",
      "        # Combine Matrices: Translation * Rotation * Scale\n",
      "        # Note: Trimesh handles multiplication order for us usually, \n",
      "        # but logically it is T @ R @ S\n",
      "        final_transform = trimesh.transformations.concatenate_matrices(\n",
      "            matrix_trans, matrix_rot, matrix_scale\n",
      "        )\n",
      "        \n",
      "        # Apply transform to mesh\n",
      "        mesh.apply_transform(final_transform)\n",
      "        \n",
      "        # Add to scene\n",
      "        scene.add_geometry(mesh, node_name=obj_id)\n",
      "\n",
      "    # 3. Export\n",
      "    # Ensure directory exists\n",
      "    output_dir = os.path.dirname(glb_output_path)\n",
      "    if output_dir and not os.path.exists(output_dir):\n",
      "        try:\n",
      "            os.makedirs(output_dir, exist_ok=True)\n",
      "            print(f\"Created directory: {output_dir}\")\n",
      "        except OSError as e:\n",
      "            print(f\"Error creating directory: {e}\")\n",
      "            return\n",
      "\n",
      "    print(f\"Exporting GLB to: {glb_output_path}\")\n",
      "    scene.export(glb_output_path)\n",
      "    print(\"Generation Complete.\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Create the data file (per requirement to load it externally)\n",
      "    create_sample_data_file()\n",
      "    \n",
      "    # Run the generator\n",
      "    process_dice_twin(INPUT_FILENAME, OUTPUT_PATH)\n",
      "```\n",
      "\n",
      "Total processing time: 39.8722 seconds\n"
     ]
    }
   ],
   "source": [
    "# [Step 6] GLB 생성(2)\n",
    "\n",
    "# trimesh 또는 numpy 라이브러리\n",
    "json_vr = \"/Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step5_vr.json\"\n",
    "with open(json_vr, \"r\", encoding=\"utf-8\") as f:\n",
    "    json_vr = json.load(f) \n",
    "result_glb = \"/Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/5_GenCode/dice_digital_twin.glb\"\n",
    "\n",
    "prompt_glb_reusable = textwrap.dedent(f\"\"\"\\\n",
    "    **Role:** Python 3D Developer\n",
    "    **Task:** Write a Python script to generate '{result_glb}'.\n",
    "\n",
    "    **Crucial Requirement (Dynamic Loading):**\n",
    "    1. Do NOT hardcode the data inside the script.\n",
    "    2. The script must **load** data from a generic JSON file named **'{json_vr}'**.\n",
    "    3. Iterate through `data['objects']` and create 3D cubes using `trimesh`.\n",
    "    - Map 'transform' > 'position' directly to the mesh.\n",
    "    - Map 'properties' > 'color' to the mesh visual.\n",
    "\n",
    "    **Output:** Provide the robust Python code.\n",
    "    \"\"\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "client_pro = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "json_glb_reusable = client_pro.models.generate_content(\n",
    "    model=\"gemini-3-pro-preview\",\n",
    "    contents=[\n",
    "        prompt_glb_reusable, \n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=1.0, #코딩 능력 극대화\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=1024), #좌표계 변환 로직 수\n",
    "    )\n",
    ")\n",
    "print(json_glb_reusable.text) # 디버깅용 출력\n",
    "print(f\"\\nTotal processing time: {(time.time() - start_time):.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b42a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Python script saved to: /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/output/50_step6_make_glb_2.py\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./output/\"\n",
    "output_filename = \"50_step6_make_glb_2.py\"\n",
    "full_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "# 마크다운 태그 제거\n",
    "clean_code = json_glb_reusable.text.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "# 파일 쓰기\n",
    "with open(full_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(clean_code)\n",
    "\n",
    "print(f\"✅ Python script saved to: {os.path.abspath(full_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32621e",
   "metadata": {},
   "source": [
    "## STEP7 -> glb 생성(주사위 전용 3D)\n",
    "step6에서 만든 파일 수정: 하나의 파일로 다양한 json 데이터 기반 glb 파일 생성 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c76790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2 objects...\n",
      "Exporting GLB to: /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/5_GenCode/dice_digital_twin.glb\n",
      "Generation Complete.\n",
      "🎉 GLB 생성 완료! 저장 경로: /Users/carol/Desktop/worktest/ai_coding/robotics_test2/notebooks/5_GenCode/dice_digital_twin.glb\n"
     ]
    }
   ],
   "source": [
    "# 3d 생성 Python Script\n",
    "\n",
    "# pip install trimesh numpy scipy\n",
    "\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILENAME = './output/50_step5_vr.json'\n",
    "OUTPUT_PATH = './output/dice_digital_twin.glb'\n",
    "\n",
    "def get_color_rgba(color_name):\n",
    "    \"\"\"Maps string color names to RGBA 0-255 values.\"\"\"\n",
    "    cmap = {\n",
    "        'red':   [255, 0, 0, 255],\n",
    "        'white': [240, 240, 240, 255], # Slightly off-white for better visibility\n",
    "        'blue':  [0, 0, 255, 255],\n",
    "        'green': [0, 255, 0, 255],\n",
    "        \"yellow\": [255, 255, 0, 255],\n",
    "        \"orange\": [255, 165, 0, 255],\n",
    "        \"pink\":   [255, 192, 203, 255],\n",
    "        # 'black': [20, 20, 20, 255],\n",
    "    }\n",
    "    return cmap.get(color_name.lower(), [128, 128, 128, 255]) # Default gray\n",
    "\n",
    "def process_dice_twin(json_input_path, glb_output_path):\n",
    "    # 1. Dynamic Loading: Read from external JSON file\n",
    "    if not os.path.exists(json_input_path):\n",
    "        raise FileNotFoundError(f\"Input file not found: {json_input_path}\")\n",
    "        \n",
    "    with open(json_input_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Initialize Scene\n",
    "    scene = trimesh.Scene()\n",
    "    \n",
    "    # 2. Iterate through objects\n",
    "    objects = data.get('objects', [])\n",
    "    print(f\"Processing {len(objects)} objects...\")\n",
    "\n",
    "    for obj in objects:\n",
    "        obj_id = obj.get('id', 'unknown')\n",
    "        props = obj.get('properties', {})\n",
    "        trans = obj.get('transform', {})\n",
    "        \n",
    "        # Geometry Creation\n",
    "        # We assume 'dice' is a cube. Let's give it a base size.\n",
    "        # Since positions are around ~80 units, a size of 4.0 ensures visibility.\n",
    "        mesh = trimesh.creation.box(extents=[4.0, 4.0, 4.0])\n",
    "        \n",
    "        # Apply Color\n",
    "        color_name = props.get('color', 'gray')\n",
    "        rgba = get_color_rgba(color_name)\n",
    "        mesh.visual.face_colors = rgba\n",
    "        \n",
    "        # -------------------------------------------------\n",
    "        # Transform Logic\n",
    "        # -------------------------------------------------\n",
    "        \n",
    "        # Position\n",
    "        pos_data = trans.get('position', {'x': 0, 'y': 0, 'z': 0})\n",
    "        translation = [pos_data['x'], pos_data['y'], pos_data['z']]\n",
    "        \n",
    "        # Rotation (Euler Degrees -> Radians -> Matrix)\n",
    "        rot_data = trans.get('rotation', {'x': 0, 'y': 0, 'z': 0})\n",
    "        # Converting degrees to radians\n",
    "        euler_angles = np.radians([rot_data['x'], rot_data['y'], rot_data['z']])\n",
    "        # Create rotation matrix (Assuming standard XYZ order)\n",
    "        matrix_rot = trimesh.transformations.euler_matrix(\n",
    "            euler_angles[0], euler_angles[1], euler_angles[2], axes='sxyz'\n",
    "        )\n",
    "        \n",
    "        # Scale\n",
    "        scale_data = trans.get('scale', {'x': 1, 'y': 1, 'z': 1})\n",
    "        matrix_scale = np.eye(4)\n",
    "        matrix_scale[0,0] = scale_data['x']\n",
    "        matrix_scale[1,1] = scale_data['y']\n",
    "        matrix_scale[2,2] = scale_data['z']\n",
    "        \n",
    "        # Translation Matrix\n",
    "        matrix_trans = trimesh.transformations.translation_matrix(translation)\n",
    "        \n",
    "        # Combine Matrices: Translation * Rotation * Scale\n",
    "        # Note: Trimesh handles multiplication order for us usually, \n",
    "        # but logically it is T @ R @ S\n",
    "        final_transform = trimesh.transformations.concatenate_matrices(\n",
    "            matrix_trans, matrix_rot, matrix_scale\n",
    "        )\n",
    "        \n",
    "        # Apply transform to mesh\n",
    "        mesh.apply_transform(final_transform)\n",
    "        \n",
    "        # Add to scene\n",
    "        scene.add_geometry(mesh, node_name=obj_id)\n",
    "\n",
    "    # 3. Export\n",
    "    # Ensure directory exists\n",
    "    output_dir = os.path.dirname(glb_output_path)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        try:\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            print(f\"Created directory: {output_dir}\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error creating directory: {e}\")\n",
    "            return\n",
    "\n",
    "    print(f\"Exporting GLB to: {glb_output_path}\")\n",
    "    scene.export(glb_output_path)\n",
    "    print(\"Generation Complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the generator\n",
    "    if os.path.exists(INPUT_FILENAME):\n",
    "        process_dice_twin(INPUT_FILENAME, OUTPUT_PATH)\n",
    "        print(f\"🎉 GLB 생성 완료! 저장 경로: {OUTPUT_PATH}\")\n",
    "    else:\n",
    "        print(f\"⚠️ 오류: 데이터 파일이 없습니다. {INPUT_FILENAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c160d0",
   "metadata": {},
   "source": [
    "# 위 GLB결과물; **VR서버 전달** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로봇팔사진으로 검증"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
